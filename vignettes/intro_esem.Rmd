---
title: "Introduction to ESEM"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to ESEM}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

## What is ESEM

ESEM is ...

The theoretical aspect of ESEM is covered in Marsh et al. (REFERENCE)
The ESEM-within-CFA is explained in Morin et al. 

The bifactor ESEM is demonstrated in Howard et al. (2018) and H-ESEM  in Morin and Asparouhov (2018)

## General steps to complete ESEM

Step 1. Data Screening, Cleaning, and Preparation

Step 2. Determine the Most Appropriate Software,Estimator, Rotations, and Procedure

## The package

The package was developed to simplify the operational aspect of ESEM: instead of loading and using several packages, the package is a all-in-one access to steps required for ESEM with both approaches, "normal" ESEM and ESEM-within-CFA, as well as it provides access to other ESEM approaches, such as H-ESEM and bifactor ESEM (Howard et al. (2018)) 

## How to use the package

- Install the package using the following code:
Before running the code, you need to install `remotes` package

```{r eval=FALSE}
#install.packages("remotes")
library(tidyverse)
```

```{r}
remotes::install_github("maria-pro/esem", build_vignettes = TRUE)
library(esem)
```

#### Definitions:

**Measurement invariance** (= **measurement equivalence**) assumes that the same construct can be measured across some specified groups. It ensures consistency in interpretation of the results when the same instrument is used for different groups. For CFA and SEM, it can also be called "factorial invariance".

The measurement invariance relates to:

- *Equal form*: The number of factors and the pattern of factor-indicator relationships are identical across groups.

- *Equal loadings*: Factor loadings are equal across groups.

- *Equal intercepts*: When observed scores are regressed on each factor, the intercepts are equal across groups.

- *Equal residual variances*: The residual variances of the observed scores not accounted for by the factors are equal across groups.

**Missing values:**

You have an option to deal with missing values in data cleaning and exploration step *before* the modeling step. However, the missing values can also be dealt with in the CFA/EFA step

By default, missing values are removed with listwise deletion. 
The alternative is to use case-wise (or ‘full information’) maximum likelihood estimation by setting `missing="ML"` in the function (e.g. for MCAR (missing completely at random) or MAR (missing at random).

**Ordinal variables:**

Explicit use of ordinal variables is done in the `ordered` parameter by setting it to  `ordered = TRUE`. This set the model to treat all variables as ordinal.


**Estimation methods:**

The estimation method is set up in `estimator` parameter, e.g. `estimator = "ML"`

By default, `ML` estimator is the default one for EFA/CFA. 

Additionally, the following alternative estimators are available:

- `"GLS"`: generalized least squares. For complete data only.

- `"WLS"`: weighted least squares (sometimes called ADF estimation). For complete data only.

- `"DWLS"`: diagonally weighted least squares

- `"ULS"`: unweighted least squares

- `"DLS"`: distributionally-weighted least squares

- `"PML"`: pairwise maximum likelihood

For robust equivalents that  provide robust standard errors and a scaled test statistic, the following ones are available:

- `"MLM"`: maximum likelihood estimation with robust standard errors and a Satorra-Bentler scaled test statistic. For complete data only.

- `"MLMVS"`: maximum likelihood estimation with robust standard errors and a mean- and variance adjusted test statistic (aka the Satterthwaite approach). For complete data only.

- `"MLMV"`: maximum likelihood estimation with robust standard errors and a mean- and variance adjusted test statistic (using a scale-shifted approach). For complete data only.

- `"MLF"`: for maximum likelihood estimation with standard errors based on the first-order derivatives, and a conventional test statistic. For both complete and incomplete data.

- `"MLR"`: maximum likelihood estimation with robust (Huber-White) standard errors and a scaled test statistic that is (asymptotically) equal to the Yuan-Bentler test statistic. For both complete and incomplete data.

If you use either the `DWLS` and `ULS` estimators, the available ‘robust’ variants: `WLSM`, `WLSMVS`, `WLSMV`, `ULSM`, `ULSMVS`, `ULSMV`.


**Rotation:**

Rotations are used for EFA where m\*m restrictions need to be applied to identify the model and this is done by the rotation. CFA does not involve rations, since it already has m\*m restrictions on Lambda and Psi parameters.

The following rotation approaches are provided:

*Orthogonal rotations:*

- "none"

- "varimax"

- "quartimax"

- "bentlerT"

- "equamax"

- "varimin"

- "geominT"

- "bifactor"

*Oblique rotations:*

- "Promax" / "promax": "promax" is used to replicate the results obtained by doing EFA in SPSS. "promax" performs the normalization and then use Promax in GPArotation.

- "oblimin"

- "simplimax"

- "bentlerQ"

- "geominQ"

- "biquartimin" 

- "cluster" 

For choosing the correct rotation, these links are useful:

[Sass, D. A., & Schmitt, T. A. (2010). A comparative investigation of rotation criteria within exploratory factor analysis. Multivariate Behavioral Research, 45(1), 73–103.] (https://doi.org/10.1080/00273170903504810)

[Shiken: JALT Testing & Evaluation SIG Newsletter. 13 (3) November 2009 (p. 20 - 25)](
https://hosted.jalt.org/test/PDF/Brown31.pdf)

The default rotation for EFA function `fa()` is `rotation="oblimin"`

To compare the results with

- Mplus: By default, Mplus uses geomin oblique rotatione, but also provides additional types of rotations, available in the [Mplus User’s Guide](https://www.statmodel.com/download/usersguide/Mplus%20user%20guide%20Ver_7_r6_web.pdf)


- SPSS: By default, SPSS uses a Kaiser normalization before doing Promax. To replicate the results, use "promax" (vs "Promax") rotation.

**Model evaluation: measurement model**
Goodness-of-fit indices (CFI, TLI and RMSEA)

**Model evaluation: factorial model**

Absolute fit indices: Chi-Square 

Approximate fit indices: 
Root-Means-Square Error of Approximation (RMSEA) Standardized Root Mean Square Residual
(SRMR)

Incremental fit indices
Comparative Fit Index (CFI)
Tucker-Lewis Index (TLI),
Akaike Information Criterion (AIC)
Consistent AIC (CAIC; calculated as BIC + free parameters
Bayes Information Criterion (BIC)
Sample-Size Adjusted BIC (aBIC)

**Standard errors:**

Standard errors are (by default) based on the expected information matrix. To request robust standard errors explicitly  use `se = "robust"`. 

To explicitly requested robust test statistics use `test = "robust"`. Please see `psych` package for more options.

**Measurement model reporting:**

Item level parameters  evaluation: 
CFA models: the corrected item-total correlations (CITC) values > 0.30 
Indicators of reliability evaluation:
point-estimate composite reliability (upper-bound; ρ > 0.80) 
McDonald’s Omega (& > 0.70)


## ESEM demonstration

#### Step 0. Loading data and exploring it

The tutorial uses the SDQ-LSAC dataset, which has been cleaned, including removing cases with missing more than 10% of variables  and imputing the rest. The details of the cleaning are provided in the Appendix. We also conducted preliminary analysis of the data, including .....

The dataset is part of the package. To load the data we use

```{r}
data<-sdq_lsac
```
#!!!!!!!!!!!!!

#### Step 1. Calculating EFA derived cross-loadings 


The first step is to conduct EFA and estimate cross-loadings that will be used later in the ESEM model. We use `fa()` function and provide:

- the number of factors to estimate `nfactors` which is 5 in this case. See Appendix for additional tools available to identify the number of factors.

- select the rotation `rotate` which  is `"geominQ"` in this case. See the list of available rotations above. Since we use `geominQ`, the `delta` parameter is set to 0.5 (the default value for `delta` is 0.1).

- select the estimation method `fm` which is `ml`. See the list of available estimation methods above.

#### Demonstration

##### Models to be estimated

For demonstration purposes we are going to use the following models:

0. *Model 0*: Strict uni-dimensional model - this is a base model

1. *Model 1*: Correlated Five First-Order CFA Model comprised of PP, CP, ES, HA and PS

2. *Model 2*: Hierarchical CFA Model compromises a single Second-Order Factor of SDQ, consisting of five first-order factors

3. *Model 3*: Bifactor CFA Model of SDQ 

4. *Model 4*: Correlated Five-factor First-Order ESEM Model comprised of EPP, CP, ES, HA and PS

5. *Model 5*: Hierarchical ESEM Model compromise of a single Second-Order Factor of SDQ, made up of five first-order factors 

6. *Model 6*: Bifactor ESEM Model for SDQ 

7. *Model 7*: Correlated Five-Factor First-Order ESEM within CFA Model 1. Here, SDQ is seen as the function of five independent first-order factors (i.e. EPP, CP, ES, HA and PS). We use the starting values from Model 4 to constrain the items loadings for each independent factor.

#### Estimation approaches and rotations

All models were estimated using the maximum likelihood (ML) estimation method.

In total:

- 4 CFA models are going to be estimated (unidimensional, first-order factor, second-order factor, and bifactor) and 

- 4 ESEM models (first-order ESEM, hierarchical ESEM, bifactor ESEM, and ESEM-within-CFA)

For the CFA models: 

- For 3 CFA models (*unidimensional, first-order factor, second-order factor*) cross-loadings are constrained to zero and items load only onto their a priori theoretical factor. No rotation is applicable for CFA models by definition.

- *Bifactor CFA model* (model 3) uses a **target orthogonal rotation**. We use a general factor (G-factor) that comprises all the items of the sdq_lsac instrument. Five specific factors (S-factors) corresponding to the a priori theoretical dimensions of the SDQ were specified (i.e. EPP, CP, ES, HA and PS). 

For the ESEM models a **oblique target rotation** was used. Items load onto their a priori theoretical constructs and cross-loadings are freed but targeted to be as close to zero as possible (e.g. *model 4*).

For *hierarchical ESEM*, the ESEM-with-CFA approach was used and the original ESEM model (model 4) was re-specified as a CFA model:

1. The non-standardized loadings from model 4 were used as the starting values for model 5. 

2. Factor variances are constrained to one and one item per latent construct is constrained to be equal to model 4 ESEM item loading.

3. First-order factors are used to define a higher-order factor and determine the variance and the standardized path coefficient for each individual factor loading onto the overall SDQ. 


For the *bifactor ESEM* (i.e. model 6) we used the same strategy as for model 3. The **target orthogonal rotation** is  used and cross-loadings are freed and targeted to be as close to zero as possible. 

For the *ESEM-with-CFA* model (model 7), model 4 (i.e. original ESEM model) SDQ is a the function of five independent first-order factors:  the starting values from the initial ESEM model (i.e. model 4) are used to constrain the items loadings for each independent factor. Since the CFA framework is used, no rotation is applicable.

The syntax for model 4, 5 and 6 is generated using R.

#### Procedure

*Model 0: Unidimensional CFA Model of SDQ. * (baseline model)

A unidimensional model for overall SDQ is estimated, where all 25 items (s1_1 to s25_1R) load directly on to SDQ. 

```{r}
model0<-'SDQ =~ s1_1 + s2_1 +s3_1 + s4_1 + s5_1 + s6_1 + s7_1R + s8_1 +s9_1+ s10_1 + s11_1R + s12_1 + s13_1 + s14_1R + s15_1 + s16_1 + s17_1+ s18_1 + s19_1 + s20_1 + s21_1R + s22_1 + s23_1 + s24_1 + s25_1R'

model0.fit<- lavaan::cfa(model0, data=data, mimic =c("MPlus"), std.lv = TRUE, ordered = TRUE)

```

*Model 1*: Correlated Five Factor First-Order CFA Model comprised of PP, CP, ES, HA and PS

```{r}
model1<-'PP =~ s6_1+ s11_1R + s14_1R + s19_1 + s23_1
        CP =~  s5_1 + s7_1R + s12_1+ s18_1 + s22_1
        ES =~  s3_1 + s8_1 + s13_1 + s16_1 + s24_1
        HA =~  s2_1 + s10_1 + s15_1 + s21_1R + s25_1R
        PS =~  s1_1 + s4_1 + s9_1 + s17_1 + s20_1'

model1.fit<- lavaan::cfa(model1, data=data, mimic =c("MPlus"), std.lv = TRUE, ordered = TRUE)

```

*Model 2*: Hierarchical CFA Model compromises a single Second-Order Factor of SDQ, consisting of five first-order factors

```{r}
model2<-'PP =~ s6_1+ s11_1R + s14_1R + s19_1 + s23_1
         CP =~  s5_1 + s7_1R + s12_1+ s18_1 + s22_1
         ES =~  s3_1 + s8_1 + s13_1 + s16_1 + s24_1
         HA =~  s2_1 + s10_1 + s15_1 + s21_1R + s25_1R
         PS =~  s1_1 + s4_1 + s9_1 + s17_1 + s20_1
        
        # Second order factor SDQ
        SDQ =~ PP + CP + ES + HA + PS'

model2.fit<- lavaan::cfa(model2, data=data, mimic =c("MPlus"), std.lv = TRUE, ordered = TRUE)

```


3. *Model 3*: Bifactor CFA Model of SDQ 

We review the results by using `summary()` to view full results or using `fitMeasures` to view the global fit of a latent variable model, using the fit measures we specify in `fit.measures` argument.Alternatively, we can use `fit.measures = "all"` to view all fit measures available.

```{r}
summary(model0.fit, fit.measures = TRUE)

lavaan::fitMeasures(model0.fit, fit.measures= c("chisq.scaled", "df", "pvalue.scaled", "rmsea.scaled", "rmsea.ci.lower.scaled", "rmsea.ci.upper.scaled", "rmsea.pvalue.scaled"))

lavaan::fitMeasures(model0.fit, fit.measures="all")
```

We can next review the correlation residuals wherepairwise coefficients can help to identify possible locations of model misfit. The generated `model0.fit` object contains the residuals that can be viewed using:

```{r}
residuals(model0.fit)$cov
```

To examine various item parameter estimates we use `parameterEstimates()` function which provides parameter estimates of a latent variable model.

The `parameterEstimates()` function returns a dataframe with estimated parameters, parameters, standard errors and z-values, p-values, and the lower and upper values of the confidence intervals. We use `standardized=TRUE` to add standardized versions of the parameter estimates to the output. We filter the results to view factor loadings using `filter(op == "=~")` and select parameters of interest.

```{r}
lavaan::parameterEstimates(model0.fit, standardized=TRUE) %>% 
  filter(op == "=~") %>% 
  select(Item=rhs, Standardized=est, ci.lower, ci.upper, SE=se, Z=z, 'p-value'=pvalue)
```
The loadings indicate how much scores on an item change with a one-unit change in the latent factor. Higher loadings indicate items more sensitive to changes in levels of the latent construct.

To obtain the results of squared multiple correlations or SMCs (R2s) we can filter the output of `paraterEstimates()` function using `filter(op == "r2")`. R2s , the squared standardized loadings of items,indicate the percentage of variance of each item that is explained by the factor. The higher the percentage of variance of an item that is explained by the factor suggests that the item is a better fit at measuring the factor. 


```{r}
lavaan::parameterEstimates(model0.fit, standardized=TRUE, rsquare = TRUE) %>% 
  filter(op == "r2") %>% 
  select(Item=rhs, R2 = est) 
```
To visualise the model we use `lavaanPlot()` function with `coefs=TRUE` argument, so we can view the loadings.

```{r}
lavaanPlot::lavaanPlot(model=model0.fit, coefs = TRUE)
```

```{r}
lavaanPlot::lavaanPlot(model=model1.fit, coefs = TRUE)
```



```{r}

class(data_esem)
data_esem<-as_tibble(data_esem)
class(data_esem)

esem_efa<-psych::fa(data=esem_efa, nfactors=5)

esem_efa$loadings
Thurstone.33 <- as.matrix(Thurstone.33)
mle2 <- fa(Thurstone.33,2,rotate="none",fm="mle")
```

#### Step 2. Summarizing the EFA extracted loadings as a structural 


